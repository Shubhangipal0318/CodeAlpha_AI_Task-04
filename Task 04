import cv2
import torch
import numpy as np
from torchvision.models import detection
from torchvision.transforms import functional as F

class ObjectDetectionTracker:
    def __init__(self, model_path='yolov5s.pt', conf_threshold=0.5, iou_threshold=0.4):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)
        self.model.to(self.device)
        self.model.eval()
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.tracked_objects = {}
        self.next_id = 1

    def detect_and_track(self, frame):
        # Convert frame to RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Perform inference
        results = self.model(rgb_frame)
        
        # Extract detections
        detections = results.xyxy[0].cpu().numpy()
        
        # Filter detections based on confidence threshold
        detections = detections[detections[:, 4] >= self.conf_threshold]
        
        # Update tracked objects
        self.update_tracked_objects(detections)
        
        # Draw bounding boxes and labels
        self.draw_boxes_and_labels(frame, detections)
        
        return frame

    def update_tracked_objects(self, detections):
        if len(self.tracked_objects) == 0:
            # Initialize tracking for all detections
            for det in detections:
                self.tracked_objects[self.next_id] = {'bbox': det[:4], 'class': int(det[5]), 'ttl': 5}
                self.next_id += 1
        else:
            # Match detections with existing tracked objects
            matched_indices = []
            for det in detections:
                best_iou = 0
                best_match = None
                for obj_id, obj in self.tracked_objects.items():
                    iou = self.calculate_iou(det[:4], obj['bbox'])
                    if iou > best_iou and iou >= self.iou_threshold:
                        best_iou = iou
                        best_match = obj_id
                
                if best_match is not None:
                    self.tracked_objects[best_match]['bbox'] = det[:4]
                    self.tracked_objects[best_match]['ttl'] = 5
                    matched_indices.append(best_match)
                else:
                    self.tracked_objects[self.next_id] = {'bbox': det[:4], 'class': int(det[5]), 'ttl': 5}
                    self.next_id += 1
            
            # Remove unmatched objects or decrease their TTL
            for obj_id in list(self.tracked_objects.keys()):
                if obj_id not in matched_indices:
                    self.tracked_objects[obj_id]['ttl'] -= 1
                    if self.tracked_objects[obj_id]['ttl'] <= 0:
                        del self.tracked_objects[obj_id]

    def calculate_iou(self, box1, box2):
        x1, y1, x2, y2 = box1
        x3, y3, x4, y4 = box2
        
        xi1, yi1 = max(x1, x3), max(y1, y3)
        xi2, yi2 = min(x2, x4), min(y2, y4)
        
        intersection_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        box1_area = (x2 - x1) * (y2 - y1)
        box2_area = (x4 - x3) * (y4 - y3)
        
        iou = intersection_area / float(box1_area + box2_area - intersection_area)
        return iou

    def draw_boxes_and_labels(self, frame, detections):
        for obj_id, obj in self.tracked_objects.items():
            x1, y1, x2, y2 = obj['bbox']
            label = f"ID: {obj_id}, Class: {obj['class']}"
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

def main():
    # Initialize the object detection and tracking system
    tracker = ObjectDetectionTracker()

    # Open video capture
    cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide a video file path

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Perform object detection and tracking
        processed_frame = tracker.detect_and_track(frame)

        # Display the result
        cv2.imshow('Object Detection and Tracking', processed_frame)

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release resources
    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()